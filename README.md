## 模型地址：[HuggingFace仓库](https://huggingface.co/ruibo0/BERT_BangumiPointPredict/)
# 学习与实践历程

### 一、随机森林的理解与实现

1. **了解决策树、随机森林的原理**

    查阅相关资料，了解了决策树和随机森林的基本原理及其构建过程：决策树构建时遍历所有可能的划分位置，根据某种标准找到最优划分点，递归分裂得到子叶结点。随机森林构建时，从样本中随机选部分数据与特征构建决策树，多颗决策树投票得到最终结果，从而提高泛化能力，防止过拟合。

3. **重温python面向对象编程的语法**
  
     由于平时使用python不多，对其面向对象编程的部分语法不够了解。通过浏览w3school等网站，快速过了一遍python类与对象的相关语法。

6. **学习numpy基本语法**
  
     因有一定matlab基础，二者语法接近，此部分耗时较少。

9. **实现决策树**
   
      了解了ID3/C4.5/CART决策树的特点和各自优缺点，由于CART生成的二叉树结构简单，分类效果较好，选择构建CART分类树，使用基尼指数作为划分依据。

12. **实现随机森林**
   
      实现了Bootstrap采样与投票机制。

15. **使用iris数据集测试**
   
      下载了iris数据集，学习使用pandas读取DataFrame数据，并使用实现的随机森林进行拟合。发现拟合正确率在98%上下浮动，效果较好。
    
#### 总结
经过学习和实践，我成功实现了一个随机森林模型，并用iris数据集拟合进行了测试。通过对随机森林的实现，我不仅对决策树与随机森林有了⼀个较为深刻的理解，还学习了numpy的使用方法，学会使用python从零构建一个简单的机器学习模型。


### 二、Bangumi评论分数预测器的训练

1. **数据获取**

   通过提供的catch_data.py，爬取了Bangumi第1页和第200页共10000条评论数据，以增加数据多样性。

2. **环境配置**

   学习了python搭建虚拟环境的方法。由于个人显卡4060 8G勉勉强强能完成训练，加上不太会用云服务器，决定在本地训练，下载了CUDA, Pytorch, 以及预训练的bert-base-chinese, 配置了深度学习训练环境。

3. **了解模型微调的基本过程**

   简要了解对预训练模型进行微调的基本过程：
   - 数据处理
   - 模型加载
   - 训练循环
       - 前向传播：将输入数据传递给模型，计算输出。
       - 计算损失：比较模型输出与真实标签，计算损失值。
       - 反向传播：计算损失函数对模型参数的梯度。
       - 参数更新：使用优化器更新模型参数。
       - 学习率调整：根据调度器调整学习率。
         
4. **训练代码实现**

   由于本人水平有限，此部分有相当部分代码由AI完成。在对代码调整后，训练出模型：[HuggingFace仓库](https://huggingface.co/ruibo0/BERT_BangumiPointPredict/)

5. **模型效果评估**

   对测试集test.jsonl的数据进行测试，并比对真实分数，计算准确率。然而最终准确率并不理想，仅在20%左右。
       
#### 总结
尽管训练过程的代码在AI辅助下完成，且对其原理目前还未完全掌握，尽管最后训练的模型准确率较低，但在实践中经历数据处理、环境配置等过程，作为对深度学习没有基础的初学者，也基本实现了对模型进行微调训练的全过程，了解了深度学习的大体框架与基本原理。
